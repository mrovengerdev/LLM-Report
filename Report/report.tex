\documentclass{article}

\usepackage{tikz} 
\usetikzlibrary{automata, positioning, arrows} 

\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fullpage}
\usepackage{color}
\usepackage{parskip}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{tikz-cd}
\usepackage{textalpha}
  \hypersetup{
    colorlinks = true,
    urlcolor = blue,       % color of external links using \href
    linkcolor= blue,       % color of internal links 
    citecolor= blue,       % color of links to bibliography
    filecolor= blue,        % color of file links
    }
    
\usepackage{listings}

\lstset{escapeinside={(*@}{@*)}}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=haskell,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\newtheoremstyle{theorem}
  {\topsep}   % ABOVESPACE
  {\topsep}   % BELOWSPACE
  {\itshape\/}  % BODYFONT
  {0pt}       % INDENT (empty value is the same as 0pt)
  {\bfseries} % HEADFONT
  {.}         % HEADPUNCT
  {5pt plus 1pt minus 1pt} % HEADSPACE
  {}          % CUSTOM-HEAD-SPEC
\theoremstyle{theorem} 
   \newtheorem{theorem}{Theorem}[section]
   \newtheorem{corollary}[theorem]{Corollary}
   \newtheorem{lemma}[theorem]{Lemma}
   \newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}
   \newtheorem{definition}[theorem]{Definition}
   \newtheorem{example}[theorem]{Example}
\theoremstyle{remark}    
  \newtheorem{remark}[theorem]{Remark}

\title{CPSC-354 Report}
\author{Maxwell Rovenger  \\ Chapman University}

\date{\today} 

\begin{document}

\maketitle

\begin{abstract}
% (Delete and Replace:) You can safely delete and replace the explanations in this file as they will remain available on the course website. For example, you should replace this abstract with your own. The abstract should be a short summary of the report. It should be written in a way that makes it possible to understand the purpose of the report without reading it.  
\end{abstract}

\setcounter{tocdepth}{3}
\tableofcontents

\section{Introduction}\label{intro}

In this report, I aim to establish a comprehensive understanding of the fundamentals of programming languages through the application of Lean logic, recursion, LLMs, and parsers. This is achieved by developing a solid foundation in discrete mathematics, utilizing it to create a grammar file with Lark, and exploring how these principles act as a framework for the structure and functionality of programming languages. The report delves into the application of discrete mathematical concepts to define syntax and semantics, demonstrates the implementation of grammar using Lark for parsing, and highlights the integration of recursion and logic in constructing efficient solutions. By bridging theoretical knowledge with practical application, this report seeks to provide a holistic perspective on the fundamentals of programming languages.

\section{Week by Week}\label{homework}

\subsection{Week 1}

\subsubsection*{Notes}

Lectures introduced Lean, a programming language to help prove discrete mathematics proofs. Through using the Natural Numbers Game, we saw how Lean operates and how it works it can, with functions acting as steps, prove theorems similar to how we did in discrete math with pen and paper and induction.

\subsubsection*{Homework}

Solved problems in Natural Numbers Game using Lean to help recap teachings from Discrete Mathematics. Specifically dealing with successors and predecessors and how they can be used to change certain sides to equal the other.

\noindent
Level 5/8:
\begin{align*}
a + (b + 0) + (c + 0) & = a + b + c & {\rm by \ add\_zero} \\
a + b + (c + 0) & = a + b + c & {\rm by \ add\_zero} \\
a + b + c & = a + b + c & {\rm by \ reflexivity \ (rfl)}
\end{align*}

\noindent
Level 6/8:
\begin{align*}
a + (b + 0) + (c + 0) & = a + b + c & {\rm by \ add\_zero \ on \ c} \\
a + (b + 0) + c & = a + b + c & {\rm by \ add\_zero \ on \ b} \\
a + b + c & = a + b + c & {\rm by \ reflexivity \ (rfl)}
\end{align*}

\noindent
Level 7/8:
\begin{align*}
{\rm succ} \, n & = n + 1 & {\rm by \ one\_eq\_succ\_zero} \\
& = n + {\rm succ} \, 0 & {\rm by \ add\_succ} \\
& = {\rm succ} \, (n + 0) & {\rm by \ add\_zero} \\
& = {\rm succ} \, n & {\rm by \ reflexivity \ (rfl)}
\end{align*}

\noindent
Level 8/8:
\begin{align*}
2 + 2 & = 4 & {\rm by \ four\_eq\_succ\_three} \\
2 + 2 & = {\rm succ} \, 3 & {\rm by \ three\_eq\_succ\_two} \\
2 + 2 & = {\rm succ} \, ({\rm succ} \, 2) & {\rm by \ two\_eq\_succ\_one} \\
{\rm succ} \, 1 + {\rm succ} \, 1 & = {\rm succ} \, ({\rm succ} \, ({\rm succ} \, 1)) & {\rm by \ add\_succ} \\
{\rm succ} \, ({\rm succ} \, 1 + 1) & = {\rm succ} \, ({\rm succ} \, ({\rm succ} \, 1)) & {\rm by \ succ\_eq\_add\_one} \\
{\rm succ} \, 1 + 1 + 1 & = {\rm succ} \, ({\rm succ} \, ({\rm succ} \, 1)) & {\rm by \ succ\_eq\_add\_one} \\
1 + 1 + 1 + 1 & = {\rm succ} \, ({\rm succ} \, (1 + 1)) & {\rm by \ succ\_eq\_add\_one} \\
1 + 1 + 1 + 1 & = {\rm succ} \, (1 + 1) + 1 & {\rm by \ succ\_eq\_add\_one} \\
1 + 1 + 1 + 1 & = 1 + 1 + 1 + 1 & {\rm by \ reflexivity \ (rfl)}
\end{align*}

For level 5/8 specifically, we can see that the Lean proof, \texttt{rw[add\_zero]}, corresponds to Proof Algorithm 1: Addition, in that any variable added to zero will ultimately equal just the variable. For example: $a + 0 = a$.

From this homework, I learned how to use the Lean proof and saw how each function operated exactly like algorithms and proofs I had used in Discrete Mathematics.

\subsubsection*{Comments and Questions}

Although this week generally served as just an introduction to the curriculum and a recap of discrete mathematics, I am curious as to whether or not there was a better example to be shown of how exactly a computer uses discrete mathematics. At this point, I am knowledgeable of how discrete mathematics operates and how computers can use operators to conduct mathematical operations, but I have yet to see a direct example of a computer "thinking" through a math calculation.

If the way computers have been taught mathematics is based purely on successors and predecessors, does that make other operations like multiplication, division, and exponents far more taxing on a CPU since they have to calculate an incredible amount of successors, or do the operators used to cause multiplication and exponentiation ignore that by just creating duplicates and adding them together?

\subsection{Week 2}

\subsubsection*{Notes}

Recursion, in coding, allows for more simplistic code that is easier to read, scale, and apply. 

Regarding the allowing of typos in coding, code should be non-ambigious because coding should be universal and should work the same within the same virtual machine regardless of how you access it. We see examples of this in GitHub's copilot since it only makes suggestions that are non-ambigious and can work on any machine, as long as they have the correct virtual machine.

Lean contains tactics, Ex: rw, and theorems, Ex: one\_eq\_succ\_zero. Tactics are commands while theorems are logical propositions.

\subsubsection*{Homework}

\noindent
Level 1/5:
\begin{align*}
0 + n & = n & {\rm by \ induction \ on \ } n \\
0 + 0 & = 0 & {\rm by \ add\_zero} \\
0 & = 0 & {\rm by \ reflexivity \ (rfl)} \\
0 + {\rm succ} \, d & = {\rm succ} \, d & {\rm by \ add\_succ} \\
{\rm succ} \, (0 + d) & = {\rm succ} \, d & {\rm by \ induction \ hypothesis \ (hd)} \\
{\rm succ} \, d & = {\rm succ} \, d & {\rm by \ reflexivity \ (rfl)}
\end{align*}

\noindent
Level 2/5:
\begin{align*}
{\rm succ} \, a + b & = {\rm succ} \, (a + b) & {\rm by \ induction \ on \ } b \\
{\rm succ} \, a + 0 & = {\rm succ} \, (a + 0) & {\rm by \ add\_zero} \\
{\rm succ} \, a & = {\rm succ} \, a & {\rm by \ reflexivity \ (rfl)} \\
{\rm succ} \, a + {\rm succ} \, b & = {\rm succ} \, (a + {\rm succ} \, b) & {\rm by \ add\_succ} \\
{\rm succ} \, ({\rm succ} \, a + b) & = {\rm succ} \, (a + {\rm succ} \, b) & {\rm by \ induction \ hypothesis \ (n\_ih)} \\
{\rm succ} \, ({\rm succ} \, (a + b)) & = {\rm succ} \, ({\rm succ} \, (a + b)) & {\rm by \ reflexivity \ (rfl)}
\end{align*}

\noindent
Level 3/5:
\begin{align*}
a + b & = b + a & {\rm by \ induction \ on \ } b \\
a + 0 & = 0 + a & {\rm by \ add\_zero} \\
a & = 0 + a & {\rm by \ zero\_add} \\
a & = a & {\rm by \ reflexivity \ (rfl)} \\
a + {\rm succ} \, b & = {\rm succ} \, b + a & {\rm by \ add\_succ} \\
{\rm succ} \, (a + b) & = {\rm succ} \, b + a & {\rm by \ induction \ hypothesis \ (hb)} \\
{\rm succ} \, (b + a) & = {\rm succ} \, b + a & {\rm by \ succ\_add} \\
{\rm succ} \, (b + a) & = {\rm succ} \, (b + a) & {\rm by \ reflexivity \ (rfl)}
\end{align*}

\noindent
Level 4/5:
\begin{align*}
a + b + c & = a + (b + c) & {\rm by \ induction \ on \ } c \\
a + b + 0 & = a + (b + 0) & {\rm by \ add\_zero} \\
a + b & = a + b & {\rm by \ reflexivity \ (rfl)} \\
a + b + {\rm succ} \, c & = a + (b + {\rm succ} \, c) & {\rm by \ add\_succ} \\
{\rm succ} \, (a + b + c) & = a + (b + {\rm succ} \, c) & {\rm by \ add\_succ} \\
{\rm succ} \, (a + b + c) & = a + {\rm succ} \, (b + c) & {\rm by \ add\_succ} \\
{\rm succ} \, (a + b + c) & = {\rm succ} \, (a + (b + c)) & {\rm by \ induction \ hypothesis \ (hc)} \\
{\rm succ} \, (a + (b + c)) & = {\rm succ} \, (a + (b + c)) & {\rm by \ reflexivity \ (rfl)}
\end{align*}

\noindent
Level 5/5:
\begin{align*}
a + b + c & = a + c + b & {\rm by \ induction \ on \ } c \\
a + b + 0 & = a + 0 + b & {\rm by \ add\_zero \ and \ add\_zero} \\
a + b & = a + b & {\rm by \ reflexivity \ (rfl)} \\
a + b + {\rm succ} \, c & = a + {\rm succ} \, c + b & {\rm by \ add\_succ} \\
{\rm succ} \, (a + b + c) & = a + {\rm succ} \, c + b & {\rm by \ add\_succ} \\
{\rm succ} \, (a + b + c) & = {\rm succ} \, (a + c) + b & {\rm by \ succ\_add} \\
{\rm succ} \, (a + b + c) & = {\rm succ} \, (a + c + b) & {\rm by \ induction \ hypothesis \ (hc)} \\
{\rm succ} \, (a + c + b) & = {\rm succ} \, (a + c + b) & {\rm by \ reflexivity \ (rfl)}
\end{align*}

\subsubsection*{Comments and Questions}

Personally, I felt that when it comes to AI autocorrecting code, instead of being lenient towards mistyped code, AI could just simply correct the typos. This would allow for a smoother coding process wihle also creating non-ambigious code.

After playing around with the Tower of Hanoi, it is apparent that recursion is invaluable in programming. We often see it as a way to neatly write code but it can also be massive time saver as apparent with the Tower of Hanoi where instead of having to, through trial and error finding out the solution, we can just use a recursive equation and plug in our values. My question then is, in what other fields can we apply recursion, as it is becoming more apparent to me that recursion can be a form of thinking rather than a field specific method?

\subsubsection*{Lean Proof}

\begin{align*}
  a + b + c = a + (b + c) \\
  a + b + 0 = a + (b + 0) == def of + \\
  a + b = a + (b + 0) == def of + \\
  a + b = a + b \\
\end{align*}

\subsection{Week 3}

\subsubsection*{Notes}

It is impossible for a computer to prove all mathematical proofs since there are statements in arithmetic that are unclear if they are true or not and thus cannot be proved. This is due to there being proofs in mathematics that are built based upon assumption and although there are no problems found so far, they cannot be proved through ordinary means like what the computer would opt to do.

\subsubsection*{Homework}

\href{https://github.com/mrovengerdev/LLM-literature-review/blob/main/README.md}{LLM Literature Review README}

\subsubsection*{Discord Posting}

For my literature review, I used ChatGPT4 to ask questions about recursion within computer systems. More specifically, if it decreases memory usage or provides any processing speed based benefits rather than just readability or integration based benefits. Through my conversation, I learned that due to creating more and more stack frames for each iteration, recursion can actually increase memory usage. However, there is an alternative, that being tail recursion. It was developed in 1970s however it either does not have support or only has limited support for popular languages like Python and JavaScript. Thus, it was concluded that recursive functions are actually less memory efficient than iterative solutions. This surprised me as through recursion, humans are able to abstract a lot of our thinking and are able to quickly find out what the next iterative output is. This contrasts computers which require more processing power to perform recursive methods. This creates an inverse relationship where the better the human understanding, the worse the computer understanding.

\subsection{Week 4}

\subsubsection*{Notes}

An abstract syntax tree is the result of parsing and helps display the order and relationship between operators in a mathematical problem. the abstract syntax tree is the most intermediate, as it is more drawn out than both concrete syntax and a concrete syntax tree.

We can define well formed expressions through formal grammar. Since formal grammar helps to create definitions for what becomes a well-formed expression.

\subsubsection*{Homework}

\includegraphics[width=0.45\textwidth]{HW4IMG.png}

\subsubsection*{Questions and Comments}

If my understanding is correct, all formal languages are allowed to have their own alphabets and grammar that must be defined. However, we have found ourselves in a position where the majority of, if not all, programming langauges will use the same characters or symbols for operators and values. Thus, my question is if there is a protocol enforced that mandates the formal language used in a programming languages or has this all occurred just for ease of use?

\subsection{Week 5}

\subsubsection*{Notes}

In this week's lecture, we learned about the logic behind AND and how computer's process it. This shows that a proof in logic can be represented as a program in a programming language and vice versa.

Similarly, in the natural numbers game, we saw the application of these theorems which allowed us to prove theorems in Lean. So if a refresher is needed, going through the "A Lean Intro To Logic" is a good idea.

\subsubsection*{Homework}

Level 1/8:
\begin{align*}
{\rm todo\_list:}\ & P \\
{\rm exact\ todo\_list}
\end{align*}

Level 2/8:
\begin{align*}
{\rm Goal:}\ & P \land S \\
{\rm exact\ and\_intro}\ p\ s
\end{align*}

Level 3/8:
\begin{align*}
{\rm Goal:}\ & (A \land I) \land O \land U \\
{\rm exact\ and\_intro\ (and\_intro\ a\ i)\ (and\_intro\ o\ u)}
\end{align*}

Level 4/8:
\begin{align*}
{\rm Assumptions:} \\
- {\rm vm:}\ P \land S \\
{\rm have\ p := vm.left} \\
{\rm Assumptions:} \\
- {\rm vm:}\ P \land S \\
- {\rm p:}\ P \\
{\rm exact\ p}
\end{align*}

Level 5/8:
\begin{align*}
{\rm Assumptions:} \\
- {\rm h:}\ P \land Q \\
{\rm have\ q := and\_right\ h} \\
{\rm Assumptions:} \\
- {\rm h:}\ P \land Q \\
- {\rm q:}\ Q \\
{\rm exact\ q}
\end{align*}

Level 6/8:
\begin{align*}
{\rm Assumptions:} \\
- {\rm h1:}\ A \land I \\
- {\rm h2:}\ O \land U \\
{\rm have\ A := and\_left\ h1} \\
{\rm Assumptions:} \\
- {\rm h1:}\ A \land I \\
- {\rm h2:}\ O \land U \\
- {\rm A:}\ A \\
{\rm have\ U := and\_right\ h2} \\
{\rm Assumptions:} \\
- {\rm h1:}\ A \land I \\
- {\rm h2:}\ O \land U \\
- {\rm A:}\ A \\
- {\rm U:}\ U \\
{\rm exact\ and\_intro\ A\ U}
\end{align*}

Level 7/8:
\begin{align*}
{\rm Assumptions:} \\
- {\rm h:}\ (L \land ((L \land C) \land L) \land L \land L \land L) \land (L \land L) \land L \\
{\rm have\ h1 := and\_left\ h} \\
{\rm Assumptions:} \\
- {\rm h:}\ (L \land ((L \land C) \land L) \land L \land L \land L) \land (L \land L) \land L \\
- {\rm h1:}\ L \land ((L \land C) \land L) \land L \land L \land L \\
{\rm have\ h2 := and\_right\ h1} \\
{\rm Assumptions:} \\
- {\rm h:}\ (L \land ((L \land C) \land L) \land L \land L \land L) \land (L \land L) \land L \\
- {\rm h1:}\ L \land ((L \land C) \land L) \land L \land L \land L \\
- {\rm h2:}\ ((L \land C) \land L) \land L \land L \land L \\
{\rm have\ h3 := and\_left\ h2} \\
{\rm Assumptions:} \\
- {\rm h:}\ (L \land ((L \land C) \land L) \land L \land L \land L) \land (L \land L) \land L \\
- {\rm h1:}\ L \land ((L \land C) \land L) \land L \land L \land L \\
- {\rm h2:}\ ((L \land C) \land L) \land L \land L \land L \\
- {\rm h3:}\ (L \land C) \land L \\
{\rm have\ h4 := and\_left\ h3} \\
{\rm Assumptions:} \\
- {\rm h:}\ (L \land ((L \land C) \land L) \land L \land L \land L) \land (L \land L) \land L \\
- {\rm h1:}\ L \land ((L \land C) \land L) \land L \land L \land L \\
- {\rm h2:}\ ((L \land C) \land L) \land L \land L \land L \\
- {\rm h3:}\ (L \land C) \land L \\
- {\rm h4:}\ L \land C \\
{\rm have\ h5 := and\_right\ h4} \\
{\rm exact\ h5}
\end{align*}

Level 8/8:
\begin{align*}
{\rm Assumptions:} \\
- {\rm h:}\ ((P \land S) \land A) \land \neg I \land (C \land \neg O) \land \neg U \\
{\rm have\ h1 := and\_left\ h} \\
{\rm Assumptions:} \\
- {\rm h:}\ ((P \land S) \land A) \land \neg I \land (C \land \neg O) \land \neg U \\
- {\rm h1:}\ (P \land S) \land A \\
{\rm have\ h2 := and\_left\ h1} \\
{\rm Assumptions:} \\
- {\rm h:}\ ((P \land S) \land A) \land \neg I \land (C \land \neg O) \land \neg U \\
- {\rm h1:}\ (P \land S) \land A \\
- {\rm h2:}\ P \land S \\
{\rm have\ h3 := and\_right\ h1} \\
{\rm Assumptions:} \\
- {\rm h:}\ ((P \land S) \land A) \land \neg I \land (C \land \neg O) \land \neg U \\
- {\rm h1:}\ (P \land S) \land A \\
- {\rm h2:}\ P \land S \\
- {\rm h3:}\ A \\
{\rm exact\ and\_intro\ h3\ (and\_intro\ h2\ h1)}
\end{align*}


level 8/8 in Mathematical Logic
\[
\begin{aligned}
    (1) &\quad ((P \land S) \land A) \land \neg I \land (C \land \neg O) \land \neg U & \text{assumption} \\
    (2) &\quad (P \land S) \land A & \text{and\_left (1)} \\
    (3) &\quad P \land S & \text{and\_left (2)} \\
    (4) &\quad A & \text{and\_right (2)} \\
    (5) &\quad \neg I \land (C \land \neg O) \land \neg U & \text{and\_right (1)} \\
    (6) &\quad (C \land \neg O) \land \neg U & \text{and\_right (5)} \\
    (7) &\quad C \land \neg O & \text{and\_left (6)} \\
    (8) &\quad C & \text{and\_left (7)} \\
    (9) &\quad P & \text{and\_left (3)} \\
    (10) &\quad S & \text{and\_right (3)} \\
\end{aligned}
\]

\subsubsection*{Comments and Questions}

Following our exposure to proving the new theorem regarding "AND" in Lean, I took note of the recursive nature of this course. Specifically, how all topics in this course build up on each other. This lead me to asking the question: How does recursion play into isomorphism and is the scalability of recursive functions a necessity for theorems and logic within programming?


\subsection{Week 6}

\subsubsection*{Notes}

Implication is actually just a function that has to be proved through theorems and proofs rather than just visual confirmation.

Precedence: An integral part of programming languages, decides the order of operations in a mathematical problem. This is important as it can change the outcome of a problem if not done correctly.

\begin{itemize}
  \item Appraisal: Processed left-to-right
  \item $\lambda$ Abstraction: Processed right-to-left
\end{itemize}

\subsubsection*{Homework}

Level 1/9:
\begin{lstlisting}
Assumptions:
(*@ $ - bakery\_service: P \to C $ @*)
exact bakery_service p
\end{lstlisting}

Level 2/9:
\begin{lstlisting}
(*@ $ have h_1 : C \to C := fun c : C => c $ @*)
Assumptions:
(*@ $   - h_1 : C \to C $ @*)
exact h_1
\end{lstlisting}

Level 3/9:
\begin{lstlisting}
Objects:
  - I S : Prop
Goal:
(*@ $   - I \land S \to S \land I $ @*)
(*@ $ exact \lambda h : I \land S \to and_intro (and\_right h) h.left $ @*)
\end{lstlisting}

Level 4/9:
\begin{lstlisting}
Assumptions:
(*@ $   - h1 : C \to A $ @*)
(*@ $   - h2 : A \to S $ @*)
(*@ $ exact h1 \gg h2 $ @*)
\end{lstlisting}

Level 5/9:
\begin{lstlisting}
Assumptions:
  -p : P
(*@ $ - h1 : P \to Q $ @*)
(*@ $ - h2 : Q \to R $ @*)
(*@ $ - h3 : Q \to T $ @*)
(*@ $ - h4 : S \to T $ @*)
(*@ $ - h5 : T \to U $ @*)
(*@ $ exact (h1 \gg h3 \gg h5) p $ @*)
\end{lstlisting}

Level 6/9:
\begin{lstlisting}
Assumptions:
(*@ $   - h : C \land D \to S $ @*)
(*@ $ exact fun c => fun d => h \langle c,d \rangle $ @*)
\end{lstlisting}

Level 7/9:
\begin{lstlisting}
Assumptions:
(*@ $   - h : C \to D \to S $ @*)
(*@ $   exact fun \langle c, d \rangle => h c d $ @*)
\end{lstlisting}

Level 8/9:
\begin{lstlisting}
Assumptions:
(*@ $    - (S \to C) \land (S \to D) $ @*)
(*@ $  exact fun s => \langle h.1 s, h.2 s \rangle $ @*)
\end{lstlisting}

Level 9/9:
\begin{lstlisting}
Objects:
  - R S : Prop
Goal:
(*@ $   - R \to (S \to R) \land (\neg S \to R) $ @*)
(*@ $ exact fun r => \langle fun => r, fun => r \rangle $ @*)
\end{lstlisting}

\subsubsection*{Comments and Questions}

Although closing laptops allows for better lecture retention, it heavily damages the ability to take notes, decreasing the value of the report's "notes" subsection.

In class, we commonly hear the term "context-free grammar", is it not the case where all grammar within computers should be context free considering it is the foundation for mathematics which always operates the same? What are some examples of grammar that is context specific?

\subsection{Week 7}

\subsubsection*{Notes}
$\lambda$-calc: Useful helpers

\begin{enumerate}
  \item Projects: \\
    - (1a) Take 2 args \& return 1st lambax.lambday.x (lambdax.lambday.y)\\ 
    - (2a) 
  \item Erase: Take 3 args \& return 1st \& 3rd: lambdax.lambday.lambdaz.xz
  \item Duplicate: take 1 arg \& duplicate lambdax.xx
\end{enumerate}

How to encode logic in $\lambda$-calc:
\begin{enumerate}
  \item Specifications: \\
        - if-then-else true M N = M \\
        - if-then-else false M N = N \\
        - true := $\lambda$x.$\lambda$y.x \\
        - false := $\lambda$x.$\lambda$y.y \\
  \item Not: \\
        - not true = false \\
        - not false = true \\
        - not M = if-then-else M false true \\
        - not := $\lambda$x.x false true \\
\end{enumerate}

\subsubsection*{Homework}

\textbf{1) Reducing the lambda term:}

We are given the term:

\[
((\lambda m. \lambda n. m \, n) \, (\lambda f. \lambda x. f (f \, x))) \, (\lambda f. \lambda x. f (f (f \, x)))
\]

\textbf{Step 1: Apply the first function}

Apply \((\lambda m. \lambda n. m \, n)\) to \((\lambda f. \lambda x. f (f \, x))\):

\[
(\lambda m. \lambda n. m \, n) \, (\lambda f. \lambda x. f (f \, x)) = \lambda n. (\lambda f. \lambda x. f (f \, x)) \, n
\]

\[
= \lambda n. (\lambda f. \lambda x. f (f \, x)) \, n
\]

\textbf{Step 2: Apply the second function}

Now apply \(\lambda n. (\lambda f. \lambda x. f (f \, x)) \, n\) to \((\lambda f. \lambda x. f (f (f \, x)))\):

\[
(\lambda n. (\lambda f. \lambda x. f (f \, x)) \, n) \, (\lambda f. \lambda x. f (f (f \, x)))
= (\lambda f. \lambda x. f (f \, x)) \, (\lambda f. \lambda x. f (f (f \, x)))
\]

\textbf{Step 3: Apply the inner function}

Finally, apply \((\lambda f. \lambda x. f (f \, x))\) to \((\lambda f. \lambda x. f (f (f \, x)))\):

\[
(\lambda f. \lambda x. f (f \, x)) \, (\lambda f. \lambda x. f (f (f \, x))) = \lambda x. (\lambda f. \lambda x. f (f (f \, x))) (f (f \, x))
\]

This simplifies to:

\[
= \lambda x. f (f (f (f (f x))))
\]

\textbf{Final result:}

The fully reduced form is:

\[
\lambda x. f (f (f (f (f x))))
\]

\textbf{2) Explanation of the function \(\lambda m. \lambda n. m \, n\):}

The lambda term \(\lambda m. \lambda n. m \, n\) represents a higher-order function that takes two arguments. The first argument, \(m\), is a function, and the second argument, \(n\), is a value. The function applies \(m\) to \(n\). 

In the context of natural numbers, this function can be interpreted as a basic operation of applying a function \(m\) to an argument \(n\), commonly seen in **Church encoding**. Specifically, it applies \(m\) to \(n\), where \(m\) could represent a function that operates on natural numbers encoded in the lambda calculus style, and \(n\) is the number to which \(m\) is applied.

Thus, \(\lambda m. \lambda n. m \, n\) essentially represents a function that applies \(m\) to \(n\), and in the case of Church numerals, this can represent various operations on numbers, such as adding or multiplying, depending on the nature of \(m\).

\subsubsection*{Comments and Questions}

Lambda calculus seems to be extremely low level and be the defining foundation for a lot of programming calculations. With this said, how is it not its own programming language that is in use today for the sake of the fastest possible runtime, sort of similar to how assembly is the bare bones equivalent of programming.

\subsection{Week 8/9}

\subsubsection*{Notes}

Extensions of lambda calculus \\ 
- Basic logic: boolean logic, if-construct \\
- Basic arithmetic (numerals, add, exp,...) \\
Want: \\ 
- let l = local (names)s \\
- recursion

Introduce let:
Example from VSCode: \\
- let plus = $\lambda m . \lambda n.xf.\lambda x. m f(u f x)$ \\
  in let two = $\lambda f.\lambda x.f(fx)$ \\
  in let one = $\lambda f.\lambda x.fx$ \\
  in plus one two

Concrete syntax: let x = e, in ez \\
Goal: define this $\lambda$-calc (Church encoding)  but can also add this as syntectic sugar. \\
$\text{add to CFG: } c \rightarrow c \rightarrow \text{let id = e in e}$ \\
abstract syntax:

Y-combinator

$Y := fix := \lambda f.(\lambda x.f(xx))(\lambda x.f(xx))$

Claim: (fix F) is an fp of F, ie, F  $\rightarrow$ F (fix F). \\
Proof: fixF $\rightarrow (\lambda x. F (xx)) (\lambda x.F(xx))$

\subsubsection*{Homework}

Exercise 2: \\
- a b c d $\rightarrow$ (((a b) c) d) \\
  - This is because the grammar identifies that there are no parentheses and thus seeks to establish the order of operations. \\
- (a) $\rightarrow$ a \\
  - This is because the grammar identifies that there are parentheses and then seeks to simplify the equation. \\

Exercise 3: \\
  - Capture-avoiding substitution works by ensuring that when substituting a variable  x  in an expression, no free variables get mistakenly bound by a new scope. If a substitution would result in a name conflict (i.e.,  x  being replaced in a context where it is already bound), an Î±-conversion (renaming of bound variables) is performed to avoid variable capture.

\begin{lstlisting}
assert substitute(('lam', 'x', ('lam', 'y', ('var', 'x'), ('var', 'y'))), 'y', ('var', 'x')) == ('lam', 'x', ('lam', 'Var1', ('var', 'x'), ('var', 'Var1')))
print(f"SUBST {MAGENTA}(\\x.\\y.x y) [y/x]{RESET} == ('lam', 'x', ('lam', 'Var1', ('var', 'x'), ('var', 'Var1')))")

print("\nCapture-Avoiding Substitution: Test passed!\n")

print("\nevaluate(): All tests passed!\n")
\end{lstlisting}

  - Implemented by: \\
  1.	Base case: If the term is a variable and matches the one being substituted, replace it with the expression. \\
  2.	Lambda abstraction: When encountering a lambda abstraction  $\lambda y. e$ , check if the bound variable  $y$  conflicts with  $x$ . If so, rename  $y$  to a fresh variable before substituting. \\
  3.	Recursion: Perform the substitution recursively in the body of the lambda or function application, applying $\alpha$-conversion where necessary to avoid capture. \\

Exercise 4:
- When dealing with capture avoiding substitution, the expected result is not always returned. This is caused by events where there is a scope change that is unanticipated which results in an unexpected outcome.
- Not all computations return to normal form since there are computations that have forms where no reductions can occur.
  
Exercise 5:
  - The smallest $\lambda$-expression that does not reduce to normal form is an omega combinator. \\ 
    - $\omega = \lambda x.xx$ 

Exercise 6:
  - Used debugger

Exercise 7:
  \newcommand{\m}{\text{m}}
  \newcommand{\n}{\text{n}}
  \newcommand{\f}{\text{f}}
  \newcommand{\x}{\text{x}}
  \newcommand{\Var}{\text{Var}}

  - ((\m.\n. \m \n) (\f.\x. \f (\f \x))) (\f.\x. \f (\f (\f \x))) \\ 
  - Gets interpreted to \\ 
  - (\Var5.((\f.(\x.(f (f (f x))))) ((\f.(\x.(f (f (f x))))) Var5)))

Exercise 8:
\begin{verbatim}
12: eval (((\m.(\n.(m n))) (\f.(\x.(f (f x))))) (\f.(\x.(f x))))
    39: eval ((\m.(\n.(m n))) (\f.(\x.(f (f x)))))
        25: eval (\f.(\x.(f (f x))))
        19: eval (\f.(\x.(f x)))
    51: substitute ((\m.(\n.(m n))), (\f.(\x.(f (f x)))), m)
        45: eval ((\f.(\x.(f (f x)))) (\f.(\x.(f x))))
            29: eval (\f.(\x.(f x)))
            55: substitute ((\f.(\x.(f (f x)))), (\f.(\x.(f x))), f)
                38: eval (\x.(f (f x)))
                    40: substitute ((\x.(f (f x))), x, x)
                        22: eval (f (f x))
                            14: eval (f x)
\end{verbatim}

\subsubsection*{Comments and Questions}

Throughout the course, we've explored countless algorithms and calculations that work recursively. What makes it so difficult to revert any expression, that has been evaluated using a recursive algorithm, back to its original state?

In the course, we've seen that lambda expressions can be reduced into normal form, what exactly is the benefit of having theses expressions displayed in normal form?

\subsection{Week 10}

\subsubsection*{Notes}

2n $\rightarrow$ n/2 \\
2n+1 $\rightarrow$ 3n+1 \\

c(n) := { \\
  - n/2 n even \\
  - 3n+1 n odd \\
  }

Conjecture: stabilizes at 1, no matter the initial n.

Rewriting:

Purpose:
Formalism, to capture and analyze the process of transforming syntax (aka strings).

Examples: \\
\begin{itemize}
  \item High school algebra
  \item CFGs
  \item Turing machines
  \item D/NFA
  \item MIU save
  \item Cellular Automata
\end{itemize}

Definition: an abstract rewrite (or reduction) system ARS is a pair (A, R) with: \\
\begin{itemize}
  \item A: set of expressions
  \item R: set of rewrite rules
  \item R <= A x A a binary relation on A
\end{itemize}

Computational behavior: \\
- Confluence and Termination
\subsubsection*{Homework}

1) What did you find most challenging when working through Homework 8/9 and Assignment 3?

When working on Homework 8/9 and Assignment 3, I found it very challenging to both understand and make adjustments to the existing repo which we used for the evaluations.
It slowed down my progress by a considerable amount as I had to spend a lot of time understanding the codebase before I could make any changes to it.
After finally gaining understanding, I was able to make progress with the exercises and try out the debugger.

2) How did you come up with the key insight for Assignment 3?

I came up with the key insight for Assignment 3 by first understanding the problem and then breaking it down into smaller parts. This process was also enforced by the debugger as it provides the same style of problems solving where we can transform the program into bits and pieces by using the debugger's break points.

3) What is your most interesting takeaway from Homework 8/9 and Assignment 3?

The most interesting takeaway from both assignments, personally, was the fact that the smallest lambda expression that does not reduce to normal form is an omega combinator. This was interesting to me as it showed that not all computations can return to normal form which further supports the format in computation where there are exceptions for almost all rules.

\subsubsection*{Comments and Questions}

Although Langton's Ant has an emergent behavior, is it not the case where when we can visually confirm that the behavior occurs everytime, are we not able to just test the extremes and then be able to verify that this emergent behavior is just its normal behavior and true in all scenarios?

\subsection{Week 11}

\subsubsection*{Notes}

(2) Terminating if: does ntot admit an infinite computation (a1,a2,a3,...) also called; strictly normalizing.

(3) (weakly) normalizing if every element has some normal form.

Application: Termination analysis of programs $\rightarrow$ undecidable in general, but can analyze/classify using rewriting theory.

Confluent: If there is no diamond shape in the diagram, it is not confluent.

Unique NF: If we ask if there is a unique normal form, we're asking if all elements have at least one unique normal form.

Properties of ARS: Termination, Normalization, Confluence

ARS: $ba \rightarrow ab$ \\
- Is it terminating? (No infinite set)

We can tell that it is terminating if there is a decrease of length in the generating rules.

Not every computation terminates: (a,a,a,a,...)

Termination does imply noramlization.

\subsubsection*{Homework}

\subsection*{1. \( A = \emptyset \) and \( R = \emptyset \)}
\begin{itemize}
  \item \textbf{Terminating}: Yes, trivially terminating because there are no elements or relations.
  \item \textbf{Confluent}: Yes, trivially confluent.
  \item \textbf{Unique Normal Forms}: Yes, trivially has unique normal forms because there are no elements or rewrites.
\end{itemize}

\subsection*{2. \( A = \{a\} \) and \( R = \emptyset \)}
\begin{itemize}
  \item \textbf{Terminating}: Yes, trivially terminating because there are no relations to rewrite \( a \).
  \item \textbf{Confluent}: Yes, trivially confluent.
  \item \textbf{Unique Normal Forms}: Yes, \( a \) is its own normal form since there are no rewrites.
\end{itemize}

\subsection*{3. \( A = \{a\} \) and \( R = \{(a, a)\} \)}
\begin{itemize}
  \item \textbf{Terminating}: No, \( a \to a \) is a loop, so there is an infinite rewrite sequence.
  \item \textbf{Confluent}: Yes, trivially confluent because there is only one element with a single rewriting path.
  \item \textbf{Unique Normal Forms}: No, there is no unique normal form since \( a \) can be rewritten infinitely to itself.
\end{itemize}

\subsection*{4. \( A = \{a, b, c\} \) and \( R = \{(a, b), (a, c)\} \)}
\begin{itemize}
  \item \textbf{Terminating}: Yes, terminating because each element can be rewritten only a finite number of times.
  \item \textbf{Confluent}: No, not confluent because \( a \) can be rewritten to either \( b \) or \( c \), leading to different results.
  \item \textbf{Unique Normal Forms}: No, there is no unique normal form as \( a \) can reach either \( b \) or \( c \).
\end{itemize}

\subsection*{5. \( A = \{a, b\} \) and \( R = \{(a, a), (a, b)\} \)}
\begin{itemize}
  \item \textbf{Terminating}: No, because \( a \to a \) creates an infinite loop.
  \item \textbf{Confluent}: Yes, trivially confluent as there are only two elements and no branching rewrites.
  \item \textbf{Unique Normal Forms}: No, \( a \) does not have a unique normal form due to the loop.
\end{itemize}

\subsection*{6. \( A = \{a, b, c\} \) and \( R = \{(a, b), (b, b), (a, c)\} \)}
\begin{itemize}
  \item \textbf{Terminating}: No, because \( b \to b \) is a loop, allowing infinite rewrites.
  \item \textbf{Confluent}: No, not confluent because \( a \) can rewrite to either \( b \) or \( c \), leading to different results.
  \item \textbf{Unique Normal Forms}: No, since \( a \) can reach different results (either \( b \) or \( c \)).
\end{itemize}

\subsection*{7. \( A = \{a, b, c\} \) and \( R = \{(a, b), (b, b), (a, c), (c, c)\} \)}
\begin{itemize}
  \item \textbf{Terminating}: No, both \( b \to b \) and \( c \to c \) create loops.
  \item \textbf{Confluent}: No, not confluent because \( a \) can rewrite to either \( b \) or \( c \), leading to different results.
  \item \textbf{Unique Normal Forms}: No, since \( a \) can reach different results (either \( b \) or \( c \)).
\end{itemize}

\subsubsection*{Images for the above ARSs}

\begin{enumerate}
  \item Confluent: True. Terminating: True. Has unique normal forms: True.
  \item Confluent: True. Terminating: True. Has unique normal forms: False.
  \item Confluent: True. Terminating: False. Has unique normal forms: True.
  \item Confluent: True. Terminating: False. Has unique normal forms: False.
  \item Confluent: False. Terminating: True. Has unique normal forms: True.
  \item Confluent: False. Terminating: True. Has unique normal forms: False.
  \item Confluent: False. Terminating: False. Has unique normal forms: True.
  \item Confluent: False. Terminating: False. Has unique normal forms: False.
\end{enumerate}

% https://q.uiver.app/#q=WzAsNDQsWzAsMCwiMS4iXSxbMSwwLCJBIl0sWzIsMCwiQiJdLFswLDEsIjIuIl0sWzEsMSwiQSBcXGRvd25hcnJvdyJdLFsyLDEsIkIiXSxbMywxLCJBIl0sWzQsMSwiQyJdLFswLDIsIjMuIl0sWzEsMiwiQSJdLFsyLDIsIkIiXSxbMywyLCJBIl0sWzQsMiwiQyJdLFs1LDIsIkIiXSxbNiwyLCJEIl0sWzcsMiwiQyJdLFs4LDIsIkQiXSxbMCwzLCI0LiJdLFsxLDMsIkEiXSxbMiwzLCJCIl0sWzMsMywiQSJdLFs0LDMsIkMiXSxbMCw0LCI1LiJdLFsxLDQsIkEiXSxbMiw0LCJBIFxcZG93bmFycm93Il0sWzAsNSwiNi4iXSxbMCw2LCI3LiJdLFswLDcsIjguIl0sWzEsNSwiQSJdLFsyLDUsIkEiXSxbMyw1LCJBIl0sWzQsNSwiQiJdLFsxLDYsIkEiXSxbMiw2LCJBIFxcZG93bmFycm93Il0sWzMsNiwiQSJdLFs0LDYsIkIiXSxbMSw3LCJBIl0sWzIsNywiQiJdLFszLDcsIkIiXSxbNCw3LCJCIl0sWzUsNywiQSJdLFs2LDcsIkMiXSxbNyw3LCJDIl0sWzgsNywiQyJdLFsxLDIsIioiXSxbNCw1LCIqIl0sWzYsNywiKiJdLFs5LDEwXSxbMTEsMTJdLFsxMywxNCwiKiJdLFsxNSwxNiwiKiJdLFsxOCwxOSwiKiJdLFsyMCwyMSwiKiJdLFsyMywyNF0sWzI4LDI5XSxbMzAsMzEsIioiXSxbMzQsMzUsIioiXSxbMzYsMzcsIioiXSxbMzgsMzldLFs0MCw0MSwiKiJdLFs0Miw0M10sWzMyLDMzXSxbMjMsMjNdLFsyOCwyOF0sWzMyLDMyXSxbMzgsMzhdLFs0Miw0Ml1d

\[\begin{tikzcd}[cramped]
	{1.} & A & B \\
	{2.} & {A \downarrow} & B & A & C \\
	{3.} & A & B & A & C & B & D & C & D \\
	{4.} & A & B & A & C \\
	{5.} & A & {A \downarrow} \\
	{6.} & A & A & A & B \\
	{7.} & A & {A \downarrow} & A & B \\
	{8.} & A & B & B & B & A & C & C & C
	\arrow["{*}", from=1-2, to=1-3]
	\arrow["{*}", from=2-2, to=2-3]
	\arrow["{*}", from=2-4, to=2-5]
	\arrow[from=3-2, to=3-3]
	\arrow[from=3-4, to=3-5]
	\arrow["{*}", from=3-6, to=3-7]
	\arrow["{*}", from=3-8, to=3-9]
	\arrow["{*}", from=4-2, to=4-3]
	\arrow["{*}", from=4-4, to=4-5]
	\arrow[from=5-2, to=5-2, loop, in=55, out=125, distance=10mm]
	\arrow[from=5-2, to=5-3]
	\arrow[from=6-2, to=6-2, loop, in=55, out=125, distance=10mm]
	\arrow[from=6-2, to=6-3]
	\arrow["{*}", from=6-4, to=6-5]
	\arrow[from=7-2, to=7-2, loop, in=55, out=125, distance=10mm]
	\arrow[from=7-2, to=7-3]
	\arrow["{*}", from=7-4, to=7-5]
	\arrow["{*}", from=8-2, to=8-3]
	\arrow[from=8-4, to=8-4, loop, in=55, out=125, distance=10mm]
	\arrow[from=8-4, to=8-5]
	\arrow["{*}", from=8-6, to=8-7]
	\arrow[from=8-8, to=8-8, loop, in=55, out=125, distance=10mm]
	\arrow[from=8-8, to=8-9]
\end{tikzcd}\]

\subsubsection*{Comments and Questions}

After working with ARSs for this week, are we able to implement any recursive functions that have the ability to solve all of problems that we have encountered so far or are there too many exceptions for that to be the case?

\subsection{Week 12}

\subsubsection*{Notes}

Properties of ARS
\begin{enumerate}
  \item Terminating: No infinite computations.
  \item Confluence: No diamond shapes which follows the diamond property.
  \item Unique normal form: Every x has a unique normal form. Meaning, there exists a unique normal form for every element.
  \item Normalizing: Every element has a normal form. Not necessarily uniquely.
\end{enumerate}

Example:
\begin{itemize}
  \item Bubble sort (ba $\rightarrow$ ab)
  \item Calculator: evaluator for context free grammar of arithmetic
  \item $\lambda$-calculus, Beta-reduction
\end{itemize}

Church-Rosser property: If $y \overset{*}{\longleftrightarrow} z => y \downarrow z$

Confluence: $y \overset{*}{\leftarrow} x \overset{*}{\rightarrow} z => y \downarrow z$

\subsubsection*{Homework}

Exercise 1:

$ab \rightarrow ba$
\begin{itemize}
  \item The ARS terminates because once all "ab"s are converted into "ba", they can't be converted back, and thus the algorithm terminates.
  \item "ab" becomes "ba" or "abab" becomes "baba"
  \item The ARS is confluent because for any input, regardless of which "ab" is chosen to be converted to "ba", we end up with a single, predictable normal form which provides a unique result.
  \item The ARS implements a sorting specification.
\end{itemize}

Exercise 2:

$aa \rightarrow a$ \\
$bb \rightarrow a$ \\
$ab \rightarrow b$ \\
$ba \rightarrow b$ \\
\begin{itemize}
  \item This ARS terminates because the rules reduce the length of the string which will eventually reach a normal form.
  \item The normal forms are either "a" or "b" since it depends entirely on the original input string.
  \item There is no string that can reduce to both "a" and "b".
  \item The ARS is not confluent since any input will result in either "a" or "b" as the normal form which means that they do not have unique result.
  \item Strings that share the same final normal form would become equal.
  \item A string is equivalent to a if it contains an even number of "b"s, or it is equivalent to be if it contains an odd number of "b"s.
  \item Create a counter for the number of "b"s in the string. If the result of mod 2 to the counter is 0, it is even, and thus "a". However, if the counter is 1, it is odd and the result is "b".
  \item This algorithm implements a parity checker for the number of "b"s in the string.
\end{itemize}

Exercise 3:

$aa \rightarrow a$ \\
$bb \rightarrow a$ \\
$ba \rightarrow ba$ \\
$ab \rightarrow ab$ \\
\begin{itemize}
  \item This ARS does not terminate since any input "ab" or "ba" will infinitely loop between the two states since they can be converted back and forth.
  \item Strings that don't contain "ab" or "ba" will have a normal form of "a" or "b". However, strings that include "ab" or "ba" will be forced to cycle between the two and not have a normal form.
  \item Remove the rules $ab \rightarrow ab$ and $ba \rightarrow ba$ and keep the other two.
  \item The specification implemented is simplification of strings based on indempotence.
\end{itemize}

Exercise 4:

$ab \rightarrow ba$ \\
$ba \rightarrow ab$ \\
\begin{itemize}
  \item This ARS does not terminate since the rewrite rules only support an infinite cycle/loop.
  \item There are no normal forms since the strings will infinitely cycle between "ab" and "ba".
  \item $aa \rightarrow a$ $bb \rightarrow a$ $ba \rightarrow ba$ $ab \rightarrow ab$
  \item The specification implemented is dominance check.
\end{itemize}

Exercise 5:

$ab \rightarrow ba$ \\
$ba \rightarrow ab$ \\
$aa \rightarrow$ \\
$b \rightarrow$ \\
\begin{itemize}
  \item $abba \rightarrow aa \rightarrow $ \\ $bababa \rightarrow aaa \rightarrow a$
  \item The ARS is not terminating because when the ARS is caught in the cycle, it will never use the third or fourth rule, causing an infinite cycle with no termination.
  \item There are two classes. 1. Strings, whose counter of "a" mod 2 = 0, that are reduced to an empty string with a normal form of "". 2. Strings, whose counter of "a" mod 2 = 1, that are reduced to a normal form of "a".
  \item Remove the first two rules which breaks the infinite loop. This maintains the same parity and ensures that the same normal form outputs are maintained.
  \item 1. Does this string reduce to an empty string? 2. Does this string reduce to an "a"?
\end{itemize}

Exercise 5b:

$ab \rightarrow ba$ \\
$ba \rightarrow ab$ \\
$aa \rightarrow a$ \\
$b \rightarrow$ \\
\begin{itemize}
  \item $abba \rightarrow aa \rightarrow a$ \\ $bababa \rightarrow aaa \rightarrow aa \rightarrow a$
  \item The ARS is not terminating because when the ARS is caught in the cycle, it will never use the third or fourth rule, causing an infinite cycle with no termination.
  \item There are two classes. 1. Strings, that contain no "a"s, that are reduced to an empty string with a normal form of "". 2. Strings, that contain any number of "a"s, that are reduced to a normal form of "a".
  \item Remove the first two rules which breaks the infinite loop. This maintains the same parity and ensures that the same normal form outputs are maintained.
  \item 1. Does this string reduce to an empty string? 2. Does this string reduce to an "a"?
\end{itemize}

\subsubsection*{Comments and Questions}

When dealing with the normalization of ARSs, is it possible to prevent infinite loops through a designating the order in which rules must be applied or the number of times a rule can be applied?

\subsection{Week 13}

\subsubsection*{Notes}

There is a riddle where 10 people with hats, either black or white, are staring in the same direction.
This means that the person in the back can see the 9 people in front of them, the person in the 9th position can see the 8 people in front of them, and so on.
A person can only guess one color and make no other means of communication.
One mistake is allowed.

The solution is to have a person say "white", if there is an even number of white hats in front of them. Furthermore, if there is an odd number of white hats, they should say "black".

With the addition of the new grammar lark rules in milestone 2, we can begin to see the foundations of a programming language.

\subsubsection*{Homework}

\[
\begin{aligned}
1. & \quad \text{let rec } \text{fact} = \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1) \text{ in fact } 3 \\
   & \to \text{(definition of let rec)} \\
2. & \quad \text{let } \text{fact} = (\text{fix } (\lambda \text{fact}.\ \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1))) \text{ in fact } 3 \\
   & \to \text{(definition of let)} \\
3. & \quad (\lambda \text{fact}.\ \text{fact } 3) (\text{fix } (\lambda \text{fact}.\ \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1))) \\
   & \to \text{(beta reduction: substitute } \text{fact}) \\
4. & \quad (\text{fix } (\lambda \text{fact}.\ \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1)))\ 3 \\
   & \to \text{(definition of fix)} \\
5. & \quad (\lambda \text{fact}.\ \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1)) (\text{fix } (\lambda \text{fact}.\ \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1)))\ 3 \\
   & \to \text{(beta reduction: substitute } \text{fact}) \\
6. & \quad (\lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * (\text{fix } (\lambda \text{fact}.\ \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1))) (n-1))\ 3 \\
   & \to \text{(beta reduction: substitute } n) \\
7. & \quad \text{if } 3=0 \text{ then } 1 \text{ else } 3 * (\text{fix } (\lambda \text{fact}.\ \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1))) (3-1) \\
   & \to \text{(evaluate } \text{if)} \\
8. & \quad 3 * (\text{fix } (\lambda \text{fact}.\ \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1)))\ (3-1) \\
   & \to \text{(arithmetic: } 3-1) \\
9. & \quad 3 * (\text{fix } (\lambda \text{fact}.\ \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1)))\ 2 \\
   & \to \text{(definition of fix)} \\
10. & \quad 3 * ((\lambda \text{fact}.\ \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1)) (\text{fix } (\lambda \text{fact}.\ \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1))))\ 2 \\
    & \to \text{(beta reduction: substitute } \text{fact}) \\
11. & \quad 3 * (\lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * (\text{fix } (\lambda \text{fact}.\ \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1))) (n-1))\ 2 \\
    & \to \text{(beta reduction: substitute } n) \\
12. & \quad 3 * (\text{if } 2=0 \text{ then } 1 \text{ else } 2 * (\text{fix } (\lambda \text{fact}.\ \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1))) (2-1)) \\
    & \to \text{(evaluate } \text{if)} \\
13. & \quad 3 * (2 * (\text{fix } (\lambda \text{fact}.\ \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1))) (2-1)) \\
    & \to \text{(arithmetic: } 2-1) \\
14. & \quad 3 * (2 * (\text{fix } (\lambda \text{fact}.\ \lambda n.\ \text{if } n=0 \text{ then } 1 \text{ else } n * \text{fact} (n-1)))\ 1) \\
    & \to \text{(repeat steps for } n=1 \text{ and } n=0 \text{ as above)} \\
    & \to \text{(final arithmetic)} \\
15. & \quad 3 * (2 * 1) = 6
\end{aligned}
\]

\subsubsection*{Comments and Questions}

Are there any forms of recursion that we can apply towards the hat riddle that would make it simpler to solve? Even accounting for the event where there are multiple colors?

\section{Lessons from the Assignments}

\subsubsection*{Milestone 1}

From the moment of its creation, I assumed a leadership role for this project by immediately setting up a group chat to facilitate communication and coordination among team members. Next, I created the GitHub repository and established clear guidelines on how we would utilize branches to manage our work. Additionally, I separated our progress with each milestone within branches to act as an easy to use version control. This way, if our future milestones had taken a bad turn, we could just reset with the progress made in the previous milestone. This structure ensured that we could collaborate efficiently while minimizing the risk of conflicts or errors.

Beyond these organizational efforts, during the first milestone I worked closely with my teammates to implement the required modifications to the \texttt{evaluate} and \texttt{substitute} functions for the new grammar. These changes were integral to incorporating the grammar Lark file that enabled addition, multiplication, and subtraction operations. This experience deepened my understanding of how interpreters for programming languages function. Specifically, I learned how to transform equations using a grammar Lark file and manage the order of operations, ensuring that multiplication took precedence over addition. These lessons not only enhanced my technical skills but also provided valuable insights into the inner workings of interpreters.

Something I found especially noteworthy was the appearance of recursion, a topic which we had recently spoken of plenty. After viewing the code for the Tower of Hanoi solution, it became apparanent that the interpreter's task was extremely similar in almost every facet. For example, just like how the disks of the Tower of Hanoi had to follow a similar pattern, so did our interpreter. An example of this is how our interpreter needed to perform normalization to every equation before beginning to perform an operator on its components.

\subsubsection*{Milestone 2}

For the second milestone, my primary contribution was to integrate the new grammar into the existing grammar Lark file. Once again, I updated the \texttt{evaluate} and \texttt{substitute} functions to accommodate these changes. This phase of the project introduced new challenges, particularly in the realm of comparison operations. Through my work on this milestone, I gained a solid understanding of how comparisons are conducted within an interpreter and how the interpreter can compare values. More specifically, how interpreters can do so by utilizing the same mathematical thinking that was used in discrete mathematics.

Unfortunately, milestone 2 also highlighted areas where I needed additional support. Specifically, I struggled to grasp the implementation of the logic behind how parentheses works within our grammar lark file. The additional layer of priority and complete formation of PEMDAS led to confusion on my end. Recognizing my limitations, I turned to my teammates for guidance. Their explanations and contributions helped bridge my knowledge gap and ensured that we could successfully integrate parentheses into the project. I felt that this experience was a valuable learning experience as it took a strong amount of introspection to discover such a knowledge gap and allowed us to move onto the next milestone.

\subsubsection*{Milestone 3}

In the final milestone, I continued to build on my strengths by integrating the new grammar into the grammar Lark file. However, the complexity of this milestone proved to be significantly greater than the previous ones. The use of lists within the programming language was particularly challenging for me, as it required a low-level understanding that I found difficult to grasp. Despite my efforts, I was unable to derive as much learning from this milestone as I had hoped.

One of the key challenges during this phase was balancing the demands of milestone 3 with the impending final report. The deadlines combined with finals forced us to prioritize the final report during class time, which limited the time we could dedicate to fully understanding the grammar in milestone 3. Reflecting on this experience, I believe that both additional in-class time for group work and prioritizing a fleshed out group wide understanding before beginning each milestone would have been beneficial. These changes could have greatly changed the troublesome and difficult experience of milestone 3.

\section{Seminars}\label{seminars}

\subsection{Seminar Speaker: Dr. Ansel Teng}

\subsubsection*{Summary}

Dr. Ansel Teng's speaker event touched on the applications of AI in world the nonprofit organization fundraising. His works are dedicated towards a SaaS platform which utilizes both donor data and AI models to predict which people are most likely to donate, donate the most, and how to best contact them. Additionally, the SaaS also has lots of filtering which greatly increases the effectiveness of the software.

\subsubsection*{Question}

Would current donors decrease or cease donations after the realization that they are having all of their information extracted after giving a donation? And would the benefits outweigh the cost of that drawback?

\subsection{"Creating Your Own Programming Language" by Computerphile}

\subsubsection*{Summary}

I watched Computerphile's video "Creating Your Own Programming Language" which is about the process of designing a basic programming language using Python. It begins by constructing an interpreter capable of evaluating expressions with Reverse Polish Notation (RPN), employing a stack-based approach for efficient computation. As the language develops, features like variables are introduced, allowing for value assignment and reuse, along with support for multi-line code. The implementation is further enhanced with logic structures, such as loops and conditionals, which enable the interpreter to handle more complex tasks. An important section was the creation of a factorial function using a while loop, showcasing the versatility provided by combining loops and branching logic. The video also emphasizes practical techniques, such as Pythonâs split method for tokenization and the use of dictionaries for variable management. By the end, the language evolves into a functional tool capable of solving meaningful problems.

\subsubsection*{Question}

How would this programming language be created if not for the use of the C++/Python? How do you create a programming language without a programming language?

\subsection{Stratefied Design Lens by Eric Normand}

\subsubsection*{Summary}

I listened to Eric Normandâs podcast on the stratified design lens, which emphasizes that effective software development isnât about rigidly following rules but about making thoughtful design decisions by clearly separating different layers within an application. This stratified approach helps prevent a system from becoming brittle, as it allows each layer to evolve independently. Furthermore, this  It encourages thoughtful organization by placing logic where it truly belongs, making your software more adaptable and maintainable.

\subsubsection*{Question}

My Question: Is it still possible to separate the layers in a clear cut manner even when the model creates both complex rules and flexibility at the same time?

\subsection{"Programming Loops vs Recursion" by Computerphile}

\subsubsection*{Summary}

I watched the âProgramming Loops vs Recursionâ video by Computerphile, which delved into the history and progression of loops in programming. The video highlighted the shift from early assembly languages to the emergence of high-level languages like FORTRAN. As programming languages evolved, nested loops were introduced, greatly enhancing the power of loops. This concept of nesting loops laid the groundwork for understanding the importance of recursion in programming. One notable takeaway was that nested loops enabled more complex calculations, making it possible to handle multi-dimensional problems like 2D arrays. However, even with the power of nested loops, there were still limitations, leading to the need for recursion to tackle more complex tasks, such as solving Ackermannâs function. The video also touched on how recursion is fundamental to compiler development, which relates to our class where we created lambda-calculus compilers.  

\subsubsection*{Question}

Would using earlier assembly languages to teach recursion help give students a better idea of how recursion works due to the elimination of any notable abstraction?

\subsection{}

\subsubsection*{Summary}

In the Computerphile's video, "Coding a Web Server in 25 Lines," Dr. Laurence Tratt built a basic web server in Rust with just 25 lines of code. He starts off by creating a "listener" that only responds to his IP address to avoid any need to implement server security. Next up, he establishes the basic communication for a server, where when there is a request, the server listens, and there is a response. Lastly, he cuts a lot of corners and has the browser do the majority of the work for the response and is able to create a simple text response for the page with just one line.

\subsubsection*{Question}

Is this simplicity in web server design achievable with other languages that are dynamically typed such as Python?

\section{Conclusion}\label{conclusion}

From my perspective, in the wider world of software engineering, this course acts as a bridge between discrete math and any introductory python/java/c++ course. What I mean by this is that programming language seems to describe exactly how weâre able to utilize the basic calculations done in discrete math to create a programming language that uses it as building blocks. In total, it provides a solid foundation to understand exactly how computers are able to perform calculations using the most basic of operations. Additionally, this course seeks to provide students an understanding of prompt engineering and how we can use LLMs on a larger scale than just asking it a simple question; similar to how we use google.

Personally, the most interesting topic in this course was our use of grammar lark files. It was interesting to see how we could use a simple grammar file to define how the mathematical operators would work in a language. I appreciated the pacing of the unit since we first started off with implementing addition and multiplication and then moved onto division and parentheses. I also found stressing over elements such as parentheses or left-to-right priority which I had not stopped to consider the implementation of before. I believe through this unit I developed the ability to think more critically about how all of the parts work together in the lowest levels of abstraction within software. Lastly, to see the grammar come together at the end and being able to operate within the rules of PEMDAS perfectly gave a sense of accomplishment and progress regarding the course which helped build understanding and motivation towards learning more.

As for improvements in the course, I would suggest a more high-level description of each unit during their introduction so that the students have a better idea of the unit's goal. I believe that creating a basic and easy to understand goal is the first step in developing an interest in the learning of a topic. Otherwise units can just become a system where students just go through the motions without any overarching understanding of the importance of the concepts. Moving on, I understand that since LLMs are in their infancy that it is difficult to implement them. I found almost all of the coding projects to serve little purpose since it mostly involved prompt engineering randomly until all of the tests cleared. I think it would be better to use assignments that feature near complete code snippets. This way professors can minimize the amount of busy work and just require students to complete a few lines of code that solidify understanding. Since, at the end of the day the goal is understanding and not completing the grammar since it serves no purpose.

\end{document}
